{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91992\\anaconda3\\envs\\emedicalchatbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "# from langchain.vectorstores import Chroma\n",
    "# import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from huggingface_hub.file_download import hf_hub_download\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "# from ctransformers.transformers import CTransformersModel\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DirectoryLoader(r\"data/\", glob=\"*.pdf\", loader_cls=PyPDFLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb=Chroma.from_documents(documents=text,embedding=embedding,persist_directory=\"db\")\n",
    "# vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb=Chroma(persist_directory=\"db\",embedding_function=embedding)\n",
    "vectordb=Chroma.from_documents(text,embedding,persist_directory=\"db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectordb.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":7})\n",
    "# docs=retriever.get_relevant_documents(\"How to diagnose a patient?\")\n",
    "# docs\n",
    "# retriever = VectorStoreRetriever(vectorstore=vectordb,search_type=\"mmr\",search_kwargs={\"k\":4})\n",
    "# docs=retriever.get_relevant_documents(\"How to diagnose a patient?\")\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "Use the following pieces of information to answer the user's question. If you don't know the answer, just say that you don't know, don't make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=PromptTemplate(\n",
    "    input_variables=[\"context\",\"question\"],\n",
    "    template=prompt\n",
    ")\n",
    "chain_type_kwargs={\"prompt\":prompt_template}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path=hf_hub_download(repo_id=\"TheBloke/Llama-2-7B-Chat-GGML\", filename=\"llama-2-7b-chat.ggmlv3.q4_0.bin\")\n",
    "# model_path\n",
    "# llm=CTransformers(\n",
    "#     model=model_path,\n",
    "#     model_type=\"llama\",\n",
    "#     config={\n",
    "#         'max_new_tokens':512,\n",
    "#         'temperature':0.8\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(\n",
    "    model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "    model_type=\"llama\",\n",
    "    config={\n",
    "        'max_new_tokens':512,\n",
    "        'temperature':0.8\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "# qa = RetrievalQA.from_llm(llm,retriever)\n",
    "# retrievalQA = RetrievalQA.from_llm(llm=llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91992\\anaconda3\\envs\\emedicalchatbot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Number of tokens (1757) exceeded maximum context length (512).\n",
      "Number of tokens (1758) exceeded maximum context length (512).\n",
      "Number of tokens (1759) exceeded maximum context length (512).\n",
      "Number of tokens (1760) exceeded maximum context length (512).\n",
      "Number of tokens (1761) exceeded maximum context length (512).\n",
      "Number of tokens (1762) exceeded maximum context length (512).\n",
      "Number of tokens (1763) exceeded maximum context length (512).\n",
      "Number of tokens (1764) exceeded maximum context length (512).\n",
      "Number of tokens (1765) exceeded maximum context length (512).\n",
      "Number of tokens (1766) exceeded maximum context length (512).\n",
      "Number of tokens (1767) exceeded maximum context length (512).\n",
      "Number of tokens (1768) exceeded maximum context length (512).\n",
      "Number of tokens (1769) exceeded maximum context length (512).\n",
      "Number of tokens (1770) exceeded maximum context length (512).\n",
      "Number of tokens (1771) exceeded maximum context length (512).\n",
      "Number of tokens (1772) exceeded maximum context length (512).\n",
      "Number of tokens (1773) exceeded maximum context length (512).\n",
      "Number of tokens (1774) exceeded maximum context length (512).\n",
      "Number of tokens (1775) exceeded maximum context length (512).\n",
      "Number of tokens (1776) exceeded maximum context length (512).\n",
      "Number of tokens (1777) exceeded maximum context length (512).\n",
      "Number of tokens (1778) exceeded maximum context length (512).\n",
      "Number of tokens (1779) exceeded maximum context length (512).\n",
      "Number of tokens (1780) exceeded maximum context length (512).\n",
      "Number of tokens (1781) exceeded maximum context length (512).\n",
      "Number of tokens (1782) exceeded maximum context length (512).\n",
      "Number of tokens (1783) exceeded maximum context length (512).\n",
      "Number of tokens (1784) exceeded maximum context length (512).\n",
      "Number of tokens (1785) exceeded maximum context length (512).\n",
      "Number of tokens (1786) exceeded maximum context length (512).\n",
      "Number of tokens (1787) exceeded maximum context length (512).\n",
      "Number of tokens (1788) exceeded maximum context length (512).\n",
      "Number of tokens (1789) exceeded maximum context length (512).\n",
      "Number of tokens (1790) exceeded maximum context length (512).\n",
      "Number of tokens (1791) exceeded maximum context length (512).\n",
      "Number of tokens (1792) exceeded maximum context length (512).\n",
      "Number of tokens (1793) exceeded maximum context length (512).\n",
      "Number of tokens (1794) exceeded maximum context length (512).\n",
      "Number of tokens (1795) exceeded maximum context length (512).\n",
      "Number of tokens (1796) exceeded maximum context length (512).\n",
      "Number of tokens (1797) exceeded maximum context length (512).\n",
      "Number of tokens (1798) exceeded maximum context length (512).\n",
      "Number of tokens (1799) exceeded maximum context length (512).\n",
      "Number of tokens (1800) exceeded maximum context length (512).\n",
      "Number of tokens (1801) exceeded maximum context length (512).\n",
      "Number of tokens (1802) exceeded maximum context length (512).\n",
      "Number of tokens (1803) exceeded maximum context length (512).\n",
      "Number of tokens (1804) exceeded maximum context length (512).\n",
      "Number of tokens (1805) exceeded maximum context length (512).\n",
      "Number of tokens (1806) exceeded maximum context length (512).\n",
      "Number of tokens (1807) exceeded maximum context length (512).\n",
      "Number of tokens (1808) exceeded maximum context length (512).\n",
      "Number of tokens (1809) exceeded maximum context length (512).\n",
      "Number of tokens (1810) exceeded maximum context length (512).\n",
      "Number of tokens (1811) exceeded maximum context length (512).\n",
      "Number of tokens (1812) exceeded maximum context length (512).\n",
      "Number of tokens (1813) exceeded maximum context length (512).\n",
      "Number of tokens (1814) exceeded maximum context length (512).\n",
      "Number of tokens (1815) exceeded maximum context length (512).\n",
      "Number of tokens (1816) exceeded maximum context length (512).\n",
      "Number of tokens (1817) exceeded maximum context length (512).\n",
      "Number of tokens (1818) exceeded maximum context length (512).\n",
      "Number of tokens (1819) exceeded maximum context length (512).\n",
      "Number of tokens (1820) exceeded maximum context length (512).\n",
      "Number of tokens (1821) exceeded maximum context length (512).\n",
      "Number of tokens (1822) exceeded maximum context length (512).\n",
      "Number of tokens (1823) exceeded maximum context length (512).\n",
      "Number of tokens (1824) exceeded maximum context length (512).\n",
      "Number of tokens (1825) exceeded maximum context length (512).\n",
      "Number of tokens (1826) exceeded maximum context length (512).\n",
      "Number of tokens (1827) exceeded maximum context length (512).\n",
      "Number of tokens (1828) exceeded maximum context length (512).\n",
      "Number of tokens (1829) exceeded maximum context length (512).\n",
      "Number of tokens (1830) exceeded maximum context length (512).\n",
      "Number of tokens (1831) exceeded maximum context length (512).\n",
      "Number of tokens (1832) exceeded maximum context length (512).\n",
      "Number of tokens (1833) exceeded maximum context length (512).\n",
      "Number of tokens (1834) exceeded maximum context length (512).\n",
      "Number of tokens (1835) exceeded maximum context length (512).\n",
      "Number of tokens (1836) exceeded maximum context length (512).\n",
      "Number of tokens (1837) exceeded maximum context length (512).\n",
      "Number of tokens (1838) exceeded maximum context length (512).\n",
      "Number of tokens (1839) exceeded maximum context length (512).\n",
      "Number of tokens (1840) exceeded maximum context length (512).\n",
      "Number of tokens (1841) exceeded maximum context length (512).\n",
      "Number of tokens (1842) exceeded maximum context length (512).\n",
      "Number of tokens (1843) exceeded maximum context length (512).\n",
      "Number of tokens (1844) exceeded maximum context length (512).\n",
      "Number of tokens (1845) exceeded maximum context length (512).\n",
      "Number of tokens (1846) exceeded maximum context length (512).\n",
      "Number of tokens (1847) exceeded maximum context length (512).\n",
      "Number of tokens (1848) exceeded maximum context length (512).\n",
      "Number of tokens (1849) exceeded maximum context length (512).\n",
      "Number of tokens (1850) exceeded maximum context length (512).\n",
      "Number of tokens (1851) exceeded maximum context length (512).\n",
      "Number of tokens (1852) exceeded maximum context length (512).\n",
      "Number of tokens (1853) exceeded maximum context length (512).\n",
      "Number of tokens (1854) exceeded maximum context length (512).\n",
      "Number of tokens (1855) exceeded maximum context length (512).\n",
      "Number of tokens (1856) exceeded maximum context length (512).\n",
      "Number of tokens (1857) exceeded maximum context length (512).\n",
      "Number of tokens (1858) exceeded maximum context length (512).\n",
      "Number of tokens (1859) exceeded maximum context length (512).\n",
      "Number of tokens (1860) exceeded maximum context length (512).\n",
      "Number of tokens (1861) exceeded maximum context length (512).\n",
      "Number of tokens (1862) exceeded maximum context length (512).\n",
      "Number of tokens (1863) exceeded maximum context length (512).\n",
      "Number of tokens (1864) exceeded maximum context length (512).\n",
      "Number of tokens (1865) exceeded maximum context length (512).\n",
      "Number of tokens (1866) exceeded maximum context length (512).\n",
      "Number of tokens (1867) exceeded maximum context length (512).\n",
      "Number of tokens (1868) exceeded maximum context length (512).\n",
      "Number of tokens (1869) exceeded maximum context length (512).\n",
      "Number of tokens (1870) exceeded maximum context length (512).\n",
      "Number of tokens (1871) exceeded maximum context length (512).\n",
      "Number of tokens (1872) exceeded maximum context length (512).\n",
      "Number of tokens (1873) exceeded maximum context length (512).\n",
      "Number of tokens (1874) exceeded maximum context length (512).\n",
      "Number of tokens (1875) exceeded maximum context length (512).\n",
      "Number of tokens (1876) exceeded maximum context length (512).\n",
      "Number of tokens (1877) exceeded maximum context length (512).\n",
      "Number of tokens (1878) exceeded maximum context length (512).\n",
      "Number of tokens (1879) exceeded maximum context length (512).\n",
      "Number of tokens (1880) exceeded maximum context length (512).\n",
      "Number of tokens (1881) exceeded maximum context length (512).\n",
      "Number of tokens (1882) exceeded maximum context length (512).\n",
      "Number of tokens (1883) exceeded maximum context length (512).\n",
      "Number of tokens (1884) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :   InboxWhat is here!\n",
      "The question: The paper meets minimum requirements for the following the following questions or Explan answer questions based on this question:\n",
      "In this question:\n",
      "The copyright? Yes, Notebook format\n",
      "Thank you need help me this question at the question:\n",
      "The copyright.\n",
      "The copyrights:\n",
      "The copyright.\n",
      "In the question: The copyright of the following information 1:\n",
      "According aims on February 4 hours of this question:\n",
      "\n",
      "\n",
      "\n",
      "The copyright?\n",
      "Answer to the question\n",
      "Part in 1: The copyright.\n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "print(\"executing\")\n",
    "user_input=input(f\"Input prompt:\")\n",
    "result=qa({\"query\": user_input})\n",
    "print(\"Response : \",result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emedicalchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
